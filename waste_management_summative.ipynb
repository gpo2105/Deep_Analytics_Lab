{"cells":[{"cell_type":"markdown","metadata":{"id":"Z2psHklGRjNS"},"source":["# EcoSort Waste Management Assistant\n","# Module 8 Summative Lab"]},{"cell_type":"markdown","metadata":{"id":"_L1jGlvHRjNV"},"source":["## Overview\n","\n","You are a data scientist at \"EcoSort,\" a technology company that specializes in developing AI solutions for waste management. EcoSort has partnered with Metro City's waste management department to develop an intelligent waste management assistant that can help residents properly dispose of waste items so less time is spent sorting material at facilities.\n","\n","This assistant needs to:\n","\n","1. Identify waste materials from images uploaded by residents (CNN)\n","2. Classify waste items based on text descriptions provided by residents (RNN/Transformer)\n","3. Generate specific recycling instructions based on identified waste type and city policies (Generative Transformer with RAG)\n","\n","Your task is to build this integrated system using the RealWaste dataset along with generated text data that simulates real-world waste management operations."]},{"cell_type":"markdown","metadata":{"id":"jHzCo330RjNW"},"source":["## Part 1: Dataset Exploration and Preparation\n","\n","In this section, you will explore and prepare the datasets for your models."]},{"cell_type":"markdown","metadata":{"id":"K-3mzMwFRjNW"},"source":["### 1.1 Load and Explore the RealWaste Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lauhxwjTRjNW"},"outputs":[],"source":["# Import necessary libraries\n","None\n","\n","# Set random seeds for reproducibility\n","np.random.seed(42)\n","tf.random.set_seed(42)\n","random.seed(42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hf3kpV0-RjNX"},"outputs":[],"source":["# TODO: Load and explore the RealWaste dataset\n","# - Dataset structure\n","# - Distribution of waste categories\n","# - Image characteristics (resolution, quality, background)\n","\n","# Your code here"]},{"cell_type":"markdown","metadata":{"id":"vR-vCTxIRjNY"},"source":["### 1.2 Explore Text Datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HPD1AqL6RjNY"},"outputs":[],"source":["# TODO: Load and explore the waste description text data\n","# - Load waste_descriptions.csv\n","# - Analyze vocabulary and structure\n","# - Understand the distribution of categories\n","\n","# Your code here"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h5AnSw1IRjNY"},"outputs":[],"source":["# TODO: Load and explore the waste policy documents\n","# - Load waste_policy_documents.csv\n","# - Understand document organization and language\n","\n","# Your code here"]},{"cell_type":"markdown","metadata":{"id":"Mj9uiWLuRjNZ"},"source":["### 1.3 Create Data Pipelines"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5z1AWpXzRjNZ"},"outputs":[],"source":["# Run this code to setup the images properly into train, validation, and test sets\n","# Set your data directory path - update this with your actual path\n","import pathlib\n","data_dir = pathlib.Path('RealWaste')\n","\n","# Parameters\n","BATCH_SIZE = 32\n","IMG_HEIGHT = 224\n","IMG_WIDTH = 224\n","\n","# Calculate the total number of classes automatically from the directory structure\n","num_classes = len([item for item in data_dir.glob('*') if item.is_dir()])\n","print(f\"Number of classes: {num_classes}\")\n","\n","# List all class folders\n","class_names = sorted([item.name for item in data_dir.glob('*') if item.is_dir()])\n","print(f\"Class names: {class_names}\")\n","\n","# Count all images\n","image_count = len(list(data_dir.glob('*/*.jpg'))) + len(list(data_dir.glob('*/*.png')))\n","print(f\"Total images found: {image_count}\")\n","\n","# Create a dataset using tf.keras.utils.image_dataset_from_directory\n","# This will automatically split the data into training and validation sets\n","train_ds = tf.keras.utils.image_dataset_from_directory(\n","    data_dir,\n","    validation_split=0.2,  # 20% for validation\n","    subset=\"training\",\n","    seed=42,\n","    image_size=(IMG_HEIGHT, IMG_WIDTH),\n","    batch_size=BATCH_SIZE,\n","    label_mode='categorical',  # For one-hot encoded labels\n","    shuffle=True\n",")\n","\n","validation_ds = tf.keras.utils.image_dataset_from_directory(\n","    data_dir,\n","    validation_split=0.2,  # 20% for validation\n","    subset=\"validation\",\n","    seed=42,\n","    image_size=(IMG_HEIGHT, IMG_WIDTH),\n","    batch_size=BATCH_SIZE,\n","    label_mode='categorical',  # For one-hot encoded labels\n","    shuffle=True\n",")\n","\n","# Create a separate test dataset by taking part of the validation set\n","# First, let's get the number of batches in the validation set\n","val_batches = tf.data.experimental.cardinality(validation_ds)\n","test_dataset = validation_ds.take(val_batches // 2)\n","validation_ds = validation_ds.skip(val_batches // 2)\n","\n","print(f\"Number of training batches: {tf.data.experimental.cardinality(train_ds)}\")\n","print(f\"Number of validation batches: {tf.data.experimental.cardinality(validation_ds)}\")\n","print(f\"Number of test batches: {tf.data.experimental.cardinality(test_dataset)}\")\n","\n","# Configure dataset for performance\n","AUTOTUNE = tf.data.AUTOTUNE\n","\n","train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","validation_ds = validation_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","test_dataset = test_dataset.cache().prefetch(buffer_size=AUTOTUNE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CvqalC0pRjNZ"},"outputs":[],"source":["# TODO: Create a text preprocessing pipeline\n","# - Tokenization\n","# - Text cleaning\n","# - Split data into train and test\n","# - Create embeddings/features\n","\n","# Your code here"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YLuYXuxARjNZ"},"outputs":[],"source":["# TODO: Prepare documents for RAG\n","# - Document preprocessing\n","# - Create embeddings for retrieval\n","\n","# Your code here"]},{"cell_type":"markdown","metadata":{"id":"FcnO9HqoRjNZ"},"source":["## Part 2: Waste Material Classification with CNN\n","\n","In this section, you will build a CNN model to classify waste materials from images."]},{"cell_type":"markdown","metadata":{"id":"ZGuSWFkYRjNZ"},"source":["### 2.1 Preprocess Images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bHw7IWbNRjNZ"},"outputs":[],"source":["# TODO: Implement image preprocessing\n","# - Apply the preprocessing pipeline created earlier\n","\n","# Your code here"]},{"cell_type":"markdown","metadata":{"id":"Atg_s1c5RjNa"},"source":["### 2.2 Implement CNN Model with Transfer Learning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H6HPFM1mRjNa"},"outputs":[],"source":["# TODO: Select an appropriate base model and implement transfer learning\n","# - Choose from MobileNet, EfficientNet, etc.\n","# - Add custom classification layers for the 9 waste categories\n","# - Configure loss function and metrics\n","\n","# Your code here"]},{"cell_type":"markdown","metadata":{"id":"w55nRURdRjNa"},"source":["### 2.3 Train and Evaluate the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g6flDXl3RjNa"},"outputs":[],"source":["# TODO: Train the CNN model\n","# - Use appropriate batch size and epochs\n","# - Implement regularization to prevent overfitting\n","# - Monitor training and validation metrics\n","\n","# Your code here"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K2mXbdmGRjNa"},"outputs":[],"source":["# TODO: Evaluate model performance\n","# - Calculate accuracy on test set\n","# - Generate confusion matrix\n","# - Analyze error patterns\n","\n","# Your code here"]},{"cell_type":"markdown","metadata":{"id":"e93UA8VvRjNa"},"source":["### 2.4 Fine-tune the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cLTuotvjRjNa"},"outputs":[],"source":["# TODO: Tune model parameters to improve performance\n","# - Adjust learning rate\n","# - Add regularization, dropout\n","# - Modify architecture if needed\n","\n","# Your code here"]},{"cell_type":"markdown","metadata":{"id":"vOUzQm-ORjNa"},"source":["## Part 3: Waste Description Classification\n","\n","In this section, you will build a text classification model to categorize waste based on descriptions."]},{"cell_type":"markdown","metadata":{"id":"ZFvG5POxRjNa"},"source":["### 3.1 Preprocess Text Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mkl2mkbTRjNa"},"outputs":[],"source":["# TODO: Implement text preprocessing\n","# - Apply the text preprocessing pipeline created earlier\n","\n","# Your code here"]},{"cell_type":"markdown","metadata":{"id":"vBO_6HtRRjNa"},"source":["### 3.2 Implement Text Classification Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xgxh54VcRjNb"},"outputs":[],"source":["# TODO: Choose and implement a text classification model\n","# Option A: Traditional ML model (Naive Bayes, Random Forest, etc.)\n","# Option B: Fine-tune a transformer-based model (BERT, DistilBERT, etc.)\n","\n","# Your code here"]},{"cell_type":"markdown","metadata":{"id":"npFcIJCiRjNb"},"source":["### 3.3 Train and Evaluate the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9KrHYgHWRjNb"},"outputs":[],"source":["# TODO: Train the text classification model\n","# - Use appropriate training parameters\n","# - Monitor training progress\n","\n","# Your code here"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oBnmw0EYRjNb"},"outputs":[],"source":["# TODO: Evaluate model performance\n","# - Calculate accuracy on test set\n","# - Generate confusion matrix\n","# - Analyze error patterns\n","\n","# Your code here"]},{"cell_type":"markdown","metadata":{"id":"rUrqcl15RjNb"},"source":["### 3.4 Create Classification Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B0P2ReB_RjNb"},"outputs":[],"source":["# TODO: Create a function that takes a text description and returns the predicted waste category\n","\n","def classify_waste_description(description):\n","    \"\"\"\n","    Classifies a waste description into an appropriate category.\n","\n","    Args:\n","        description (str): Text description of waste item\n","\n","    Returns:\n","        str: Predicted waste category\n","    \"\"\"\n","    # Your code here\n","    pass"]},{"cell_type":"markdown","metadata":{"id":"6kV487HBRjNb"},"source":["## Part 4: Recycling Instruction Generation with RAG\n","\n","In this section, you will implement a Retrieval-Augmented Generation (RAG) system to generate recycling instructions."]},{"cell_type":"markdown","metadata":{"id":"piGWJKgiRjNb"},"source":["### 4.1 Preprocess Documents for Retrieval"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JwZA_B6_RjNb"},"outputs":[],"source":["# TODO: Prepare documents for retrieval\n","# - Process policy documents and disposal instructions\n","# - Create embeddings for efficient retrieval\n","\n","# Your code here"]},{"cell_type":"markdown","metadata":{"id":"AgzotuLDRjNb"},"source":["### 4.2 Implement RAG-based System"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F3Db6G58RjNb"},"outputs":[],"source":["# TODO: Select a pre-trained language model and implement RAG\n","# - Choose an appropriate language model\n","# - Create a retrieval mechanism\n","\n","# Your code here"]},{"cell_type":"markdown","metadata":{"id":"Uv-tCvY8RjNb"},"source":["### 4.3 Adjust and Evaluate the System"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qX5AkI7LRjNh"},"outputs":[],"source":["# TODO: Train the RAG-based system\n","# - Adjust sampling methods/parameters\n","\n","# Your code here"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O3RfCq24RjNh"},"outputs":[],"source":["# TODO: Evaluate the quality of generated instructions\n","# - Test with various waste categories\n","# - Assess relevance and accuracy\n","\n","# Your code here"]},{"cell_type":"markdown","metadata":{"id":"Wfep5M1BRjNi"},"source":["### 4.4 Create Instruction Generation Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nqy4abs1RjNi"},"outputs":[],"source":["# TODO: Create a function that takes a waste category and generates recycling instructions\n","\n","def generate_recycling_instructions(waste_category):\n","    \"\"\"\n","    Generates detailed recycling instructions for a given waste category.\n","\n","    Args:\n","        waste_category (str): Waste category\n","\n","    Returns:\n","        str: Detailed recycling instructions\n","        list: Relevant policy documents\n","    \"\"\"\n","    # Your code here\n","    pass"]},{"cell_type":"markdown","metadata":{"id":"3zkj_HTRRjNi"},"source":["## Part 5: Integrated Waste Management Assistant\n","\n","In this section, you will integrate all three models into a unified waste management assistant."]},{"cell_type":"markdown","metadata":{"id":"2Znk62hFRjNi"},"source":["### 5.1 Design Integration Architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hj_U_JbZRjNi"},"outputs":[],"source":["# TODO: Design an architecture that integrates all three models\n","# - Create interfaces between components\n","# - Handle input/output flow\n","\n","# Your code here"]},{"cell_type":"markdown","metadata":{"id":"SVKgKn85RjNi"},"source":["### 5.2 Implement Integrated Assistant"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YJYkJ8LIRjNi"},"outputs":[],"source":["# TODO: Implement the integrated waste management assistant\n","\n","def waste_management_assistant(input_data, input_type=\"image\"):\n","    \"\"\"\n","    Integrated waste management assistant that processes either images or text descriptions\n","    and returns waste classification and recycling instructions.\n","\n","    Args:\n","        input_data: Either an image file path/array or a text description\n","        input_type (str): Type of input - \"image\" or \"text\"\n","\n","    Returns:\n","        dict: Dictionary containing waste category, confidence, and recycling instructions\n","    \"\"\"\n","    # Your code here\n","    pass"]},{"cell_type":"markdown","metadata":{"id":"Rbav93z8RjNi"},"source":["### 5.3 Evaluate the Integrated System"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mj1IlIljRjNi"},"outputs":[],"source":["# TODO: Evaluate the integrated system on test cases\n","# - Test with images from test dataset\n","# - Test with text descriptions from test dataset\n","# - Assess overall performance\n","\n","# Your code here"]},{"cell_type":"markdown","metadata":{"id":"Z3w34n-1RjNi"},"source":["## Submission Guidelines\n","\n","1. Make sure all code cells are properly commented and annotated\n","2. Ensure that all functions are implemented and working correctly\n","3. Verify that all evaluation metrics are calculated and analyzed\n","4. Double-check that the integrated system works as expected\n","5. Submit your completed and annotated Jupyter notebook file\n","\n","Remember to demonstrate your understanding of the underlying concepts and provide justification for your design decisions throughout the notebook."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}